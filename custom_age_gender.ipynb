{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RBjZjEk4JFW",
        "outputId": "66a1fc1e-22b0-43a3-9a12-606459aef761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KARwKeLS4Jy_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "import tensorflow\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "#from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.applications import MobileNetV2,DenseNet121,EfficientNetV2B0\n",
        "from tensorflow.keras.applications import NASNetMobile\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Lambda,Concatenate\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras.layers import Dense, Dropout, Input, Lambda, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "import os # system-wide functions\n",
        "#os.listdir('/kaggle/input/BloodPressureDataset')\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import BatchNormalization, Dense,Input,BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout,Concatenate, Conv2D,Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "import sys\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adadelta\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z0OVCpXQ7C_6"
      },
      "outputs": [],
      "source": [
        "train_path_csv = '/content/drive/MyDrive/age_gender/train.csv'\n",
        "test_path_csv = '/content/drive/MyDrive/age_gender/test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KwmHsMGR7kSU"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(train_path_csv)\n",
        "test_df =pd.read_csv(test_path_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJdKxn2e9-mF",
        "outputId": "39e8224b-15d9-41e6-a9ee-9d344ede77c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(538, 3) (60, 3)\n"
          ]
        }
      ],
      "source": [
        "print(train_df.shape,test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GSRn48Vn-kpd",
        "outputId": "2ef9d60e-cd39-4f3b-d729-43b9037ca599"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d2b1f2c4-4c11-4008-bba1-bdf2a56c95b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34_13_M.jpg</td>\n",
              "      <td>M</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>187_19_M.jpg</td>\n",
              "      <td>M</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20_24_M.jpg</td>\n",
              "      <td>M</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>231_22_M.jpg</td>\n",
              "      <td>M</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>234_22_M.jpg</td>\n",
              "      <td>M</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2b1f2c4-4c11-4008-bba1-bdf2a56c95b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2b1f2c4-4c11-4008-bba1-bdf2a56c95b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2b1f2c4-4c11-4008-bba1-bdf2a56c95b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     image_name gender  age\n",
              "0   34_13_M.jpg      M   13\n",
              "1  187_19_M.jpg      M   19\n",
              "2   20_24_M.jpg      M   24\n",
              "3  231_22_M.jpg      M   22\n",
              "4  234_22_M.jpg      M   22"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tp6CJXlI70jI"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/drive/MyDrive/age_gender/images\"\n",
        "test_path = \"/content/drive/MyDrive/age_gender/images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wIvahnfF70Bi"
      },
      "outputs": [],
      "source": [
        "i_shape = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WaUl_M067xSA"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EbTdnWPTWqMs"
      },
      "outputs": [],
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Here, `x_set` is list of path to the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "013yFnOD7zEc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# and `y_set` are the associated classes.\n",
        "\n",
        "class TrainDataSequence(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, image_set, batch_size):\n",
        "        self.image_set = image_set\n",
        "        self.batch_size = batch_size\n",
        "        self.train_path = train_path\n",
        "        self.output_size = (224, 224)\n",
        "        self.i_shape = self.output_size[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.image_set) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_image_set = self.image_set[idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "        input_set = np.zeros((self.batch_size, *self.output_size, 3))\n",
        "        # (x, y, h, w)\n",
        "        gender_set = np.zeros((self.batch_size, 1))\n",
        "        age_set = np.empty((self.batch_size,1))\n",
        "        gender_dict = {'F':0, 'M' : 1}\n",
        "        image = []\n",
        "        gender = []\n",
        "        age = []\n",
        "        for i,file_name in enumerate(batch_image_set):\n",
        "          img = cv2.imread(os.path.join(self.train_path,file_name))\n",
        "          img = cv2.resize(img,(self.i_shape,self.i_shape))\n",
        "          input_set[i,] = img\n",
        "          gender_set[i][0] = gender_dict[file_name.split('.')[0].split('_')[-1]]\n",
        "          age_set[i][0] = int(file_name.split('.')[0].split('_')[1])\n",
        "        return input_set, {\"gender_output\" : gender_set, \"age_output\":age_set}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sofZbLGY7wvH"
      },
      "outputs": [],
      "source": [
        "train_data_sequence =  TrainDataSequence(train_df['image_name'], batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "G8_BZFp07yev"
      },
      "outputs": [],
      "source": [
        "class TestDataSequence(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, image_set, batch_size):\n",
        "        self.image_set = image_set\n",
        "        self.batch_size = batch_size\n",
        "        self.train_path = train_path\n",
        "        self.output_size = (224, 224)\n",
        "        self.i_shape = self.output_size[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.image_set) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_image_set = self.image_set[idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "        input_set = np.zeros((self.batch_size, *self.output_size, 3))\n",
        "        # (x, y, h, w)\n",
        "        gender_set = np.zeros((self.batch_size, 1))\n",
        "        age_set = np.zeros((self.batch_size,1))\n",
        "        gender_dict = {'F':0, 'M' : 1}\n",
        "        image = []\n",
        "        gender = []\n",
        "        age = []\n",
        "        for i,file_name in enumerate(batch_image_set):\n",
        "          img = cv2.imread(os.path.join(self.train_path,file_name))\n",
        "          img = cv2.resize(img,(self.i_shape,self.i_shape))\n",
        "          input_set[i,] = img\n",
        "          gender_set[i][0] = gender_dict[file_name.split('.')[0].split('_')[-1]]\n",
        "          age_set[i][0] = int(file_name.split('.')[0].split('_')[1])\n",
        "        return input_set, {\"gender_output\" : gender_set, \"age_output\":age_set}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zurXQ5K4iz7H"
      },
      "outputs": [],
      "source": [
        "test_data_sequence =  TestDataSequence(test_df['image_name'], batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1Nk7-LoPZvFE"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(Sequence):\n",
        "\n",
        "  def __init__(self, csv_file, base_dir, output_size, shuffle=False, batch_size=10):\n",
        "    \"\"\"\n",
        "    Initializes a data generator object\n",
        "      :param csv_file: file in which image names and numeric labels are stored\n",
        "      :param base_dir: the directory in which all images are stored\n",
        "      :param output_size: image output size after preprocessing\n",
        "      :param shuffle: shuffle the data after each epoch\n",
        "      :param batch_size: The size of each batch returned by __getitem__\n",
        "    \"\"\"\n",
        "    self.df = pd.read_csv(csv_file)\n",
        "    self.base_dir = base_dir\n",
        "    self.output_size = output_size\n",
        "    self.shuffle = shuffle\n",
        "    self.batch_size = batch_size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indices = np.arange(len(self.df))\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.indices)\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(len(self.df) / self.batch_size)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    ## Initializing Batch\n",
        "    #  that one in the shape is just for a one channel images\n",
        "    # if you want to use colored images you might want to set that to 3\n",
        "    X = np.empty((self.batch_size, *self.output_size, 3))\n",
        "    # (x, y, h, w)\n",
        "    y = np.empty((self.batch_size, 4, 1))\n",
        "    print(y.shape)\n",
        "    # get the indices of the requested batch\n",
        "    indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "\n",
        "    for i, data_index in enumerate(indices):\n",
        "      img_path = os.path.join(self.base_dir,\n",
        "                  self.df.iloc[data_index, 0])\n",
        "\n",
        "      #img = mpimg.imread()\n",
        "      #img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # to reduce it to one channel to match the shape\n",
        "      ## this is where you preprocess the image\n",
        "      ## make sure to resize it to be self.output_size\n",
        "\n",
        "      label = self.df.iloc[data_index, 1:].to_numpy()\n",
        "      ## if you have any preprocessing for\n",
        "      ## the labels too do it here\n",
        "\n",
        "      #X[i,] = img\n",
        "      #y[i] = label\n",
        "\n",
        "    return X, y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "e6GRAmiqaDfe"
      },
      "outputs": [],
      "source": [
        "#train_gen = DataGenerator(\"data.csv\", \"data\", (244, 244), batch_size=20, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wRBq_IaQTn5J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oUpZ764J85qR"
      },
      "outputs": [],
      "source": [
        "def extractor_model(input_shape):\n",
        "\n",
        "    #vgg_16 = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "#     vgg_16 = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "    #vgg_16.trainable = True\n",
        "    #x = vgg_16.output\n",
        "    mob = ResNet50V2(weights = 'imagenet')\n",
        "    #mob = Xception(weights = 'imagenet')\n",
        "    #mob = MobileNetV2(weights = 'imagenet')\n",
        "    #mob = DenseNet121(weights = 'imagenet')\n",
        "    #mob = NASNetMobile(weights = 'imagenet')\n",
        "    #mob = EfficientNetV2B0(weights = 'imagenet')\n",
        "    #mob = InceptionV3(weights = 'imagenet')\n",
        "    mob.trainable = True\n",
        "    x = mob.output\n",
        "    x = Flatten(name=\"flatten\")(x)\n",
        "    # x = Dense(512, activation='relu')(x)\n",
        "    # x = Dropout(0.3)(x)\n",
        "    #output_layer = Dense(128, activation='relu')(x)\n",
        "#     x = Dense(64, activation='relu')(x)\n",
        "\n",
        "    # output_layer = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=mob.input, outputs=x)\n",
        "\n",
        "    # model.compile(optimizer=optimizer,\n",
        "    #               loss='binary_crossentropy',\n",
        "    #               metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "en4rFGS09BTe"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape):\n",
        "  #print(input_shape)\n",
        "  base_model = extractor_model(input_shape)\n",
        "  #print(base_model.summary())\n",
        "  input_image = Input(shape=input_shape)\n",
        "  feat_image = base_model(input_image)\n",
        "\n",
        "\n",
        "  gender = Dense(800,activation=\"relu\")(feat_image)\n",
        "  gender = Dropout(0.5)(gender)\n",
        "  '''\n",
        "  gender = Dense(600,activation=\"relu\")(gender)\n",
        "  gender = Dropout(0.3)(gender)\n",
        "  gender = Dense(400,activation=\"relu\")(gender)\n",
        "  gender = Dropout(0.6)(gender)\n",
        "  '''\n",
        "  gender = Dense(200,activation=\"relu\")(gender)\n",
        "  gender = Dropout(0.5)(gender)\n",
        "  gender = Dense(100,activation=\"relu\")(gender)\n",
        "  gender = Dropout(0.2)(gender)\n",
        "  '''\n",
        "  gender = Dense(50,activation=\"relu\")(gender)\n",
        "  gender = Dropout(0.5)(gender)\n",
        "  gender = Dense(25,activation=\"relu\")(gender)\n",
        "  gender = Dropout(0.7)(gender)\n",
        "  '''\n",
        "  gender = Dense(12,activation=\"relu\")(gender)\n",
        "  gender = Dropout(0.5)(gender)\n",
        "  gender = Dense(1,activation=\"sigmoid\",name = \"Gender_output_layer\")(gender)\n",
        "\n",
        "\n",
        "  age = Dense(800,activation=\"relu\")(feat_image)\n",
        "  age = Dropout(0.5)(age)\n",
        "  '''\n",
        "  age = Dense(600,activation=\"relu\")(age)\n",
        "  age = Dropout(0.3)(age)\n",
        "  age = Dense(400,activation=\"relu\")(age)\n",
        "  age = Dropout(0.6)(age)\n",
        "  '''\n",
        "  age = Dense(200,activation=\"relu\")(age)\n",
        "  age = Dropout(0.5)(age)\n",
        "  age = Dense(100,activation=\"relu\")(age)\n",
        "  age = Dropout(0.2)(age)\n",
        "  '''\n",
        "  age = Dense(50,activation=\"relu\")(age)\n",
        "  age = Dropout(0.5)(age)\n",
        "  age = Dense(25,activation=\"relu\")(age)\n",
        "  age = Dropout(0.7)(age)\n",
        "  '''\n",
        "  age = Dense(12,activation=\"relu\")(age)\n",
        "  age = Dropout(0.5)(age)\n",
        "  age = Dense(1,activation=\"linear\",name = 'Age_output_layer')(age)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model = Model(input_image, outputs= {\"gender_output\" : gender, \"age_output\": age})\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pxxiNyudWDKg"
      },
      "outputs": [],
      "source": [
        "def custom_create_model_given(input_shape):\n",
        "  input_image = Input(shape=input_shape)\n",
        "  '''\n",
        "  #mix age-gender section\n",
        "  mix_sec1 = Conv2D(filters=512, kernel_size=3, activation='relu')(input_image)\n",
        "  mix_sec1 = Conv2D(filters=512, kernel_size=3, activation='relu')(mix_sec1)\n",
        "  mix_sec1 = BatchNormalization()(mix_sec1)\n",
        "\n",
        "  mix_sec2 = MaxPooling2D(pool_size = 2)(mix_sec1)\n",
        "\n",
        "  mix_sec3 = Conv2D(filters=256, kernel_size=3, activation='relu')(mix_sec2)\n",
        "  mix_sec3 = Conv2D(filters=256, kernel_size=3, activation='relu')(mix_sec3)\n",
        "  mix_sec3 = BatchNormalization()(mix_sec3)\n",
        "\n",
        "  mix_sec4 = MaxPooling2D(pool_size = 2)(mix_sec3)\n",
        "\n",
        "  mix_sec5 = Conv2D(filters=128, kernel_size=3, activation='relu')(mix_sec4)\n",
        "  mix_sec5 = Conv2D(filters=128, kernel_size=3, activation='relu')(mix_sec5)\n",
        "  mix_sec5 = BatchNormalization()(mix_sec5)\n",
        "\n",
        "  mix_sec6 = MaxPooling2D(pool_size = 2)(mix_sec5)\n",
        "\n",
        "  mix_sec7 = Conv2D(filters=64, kernel_size=3, activation='relu')(mix_sec6)\n",
        "  mix_sec7 = Conv2D(filters=64, kernel_size=3, activation='relu')(mix_sec7)\n",
        "  mix_sec7 = BatchNormalization()(mix_sec7)\n",
        "\n",
        "  mix_sec8 = MaxPooling2D(pool_size=2)(mix_sec7)\n",
        "  '''\n",
        "\n",
        "\n",
        "  #only gender section\n",
        "  gender_sec1 = Conv2D(filters=512, kernel_size=3, activation='relu')(input_image)\n",
        "  #gender_sec1 = Conv2D(filters=512, kernel_size=3, activation='relu')(gender_sec1)\n",
        "  gender_sec1 = BatchNormalization()(gender_sec1)\n",
        "\n",
        "  gender_sec2 = MaxPooling2D(pool_size = 2)(gender_sec1)\n",
        "  #gender_sec2 = Concatenate(axis= 1)([gender_sec2,mix_sec2])\n",
        "\n",
        "  gender_sec3 = Conv2D(filters=256, kernel_size=3, activation='relu')(gender_sec2)\n",
        "  #gender_sec3 = Conv2D(filters=256, kernel_size=3, activation='relu')(gender_sec3)\n",
        "  gender_sec3 = BatchNormalization()(gender_sec3)\n",
        "\n",
        "  gender_sec4 = MaxPooling2D(pool_size = 2)(gender_sec3)\n",
        "  #gender_sec4 = Concatenate(axis= 1)([gender_sec4,mix_sec4])\n",
        "\n",
        "  gender_sec5 = Conv2D(filters=128, kernel_size=3, activation='relu')(gender_sec4)\n",
        "  #gender_sec5 = Conv2D(filters=128, kernel_size=3, activation='relu')(gender_sec5)\n",
        "  gender_sec5 = BatchNormalization()(gender_sec5)\n",
        "\n",
        "  gender_sec6 = MaxPooling2D(pool_size = 2)(gender_sec5)\n",
        "  #gender_sec6 = Concatenate(axis= 1)([gender_sec6,mix_sec6])\n",
        "\n",
        "  gender_sec7 = Conv2D(filters=64, kernel_size=3, activation='relu')(gender_sec6)\n",
        "  #gender_sec7 = Conv2D(filters=64, kernel_size=3, activation='relu')(gender_sec7)\n",
        "  gender_sec7 = BatchNormalization()(gender_sec7)\n",
        "\n",
        "  gender_sec8 = MaxPooling2D(pool_size=2)(gender_sec7)\n",
        "  #gender_sec8 = Concatenate(axis= 1)([gender_sec8,mix_sec8])\n",
        "\n",
        "  gender_sec9 = Conv2D(filters=32, kernel_size=3, activation='relu')(gender_sec8)\n",
        "  gender_sec9 = Conv2D(filters=32, kernel_size=3, activation='relu')(gender_sec9)\n",
        "  gender_sec9 = BatchNormalization()(gender_sec9)\n",
        "\n",
        "  gender_sec10 = Conv2D(filters=32, kernel_size=3, activation='relu')(gender_sec9)\n",
        "  gender_sec10 = Conv2D(filters=32, kernel_size=3, activation='relu')(gender_sec10)\n",
        "  gender_sec10 = BatchNormalization()(gender_sec10)\n",
        "\n",
        "  gender_sec11 = Flatten(name = 'gender_flatten')(gender_sec10)\n",
        "\n",
        "  gender_sec12 = Dense(1024,activation=\"relu\")(gender_sec11)\n",
        "  gender_sec12 = Dropout(0.5)(gender_sec12)\n",
        "  gender_sec12 = Dense(512,activation=\"relu\")(gender_sec12)\n",
        "  gender_sec12 = Dense(256,activation=\"relu\")(gender_sec12)\n",
        "  gender_sec12 = Dropout(0.5)(gender_sec12)\n",
        "  gender_sec12 = Dense(128,activation=\"relu\")(gender_sec12)\n",
        "  gender_sec12 = Dense(64,activation=\"relu\")(gender_sec12)\n",
        "  gender_sec12 = Dropout(0.5)(gender_sec12)\n",
        "  gender_sec12 = Dense(1,activation=\"sigmoid\",name = \"Gender_output_layer\")(gender_sec12)\n",
        "\n",
        "\n",
        "\n",
        "  #only age section\n",
        "  age_sec1 = Conv2D(filters=512, kernel_size=3, activation='relu')(input_image)\n",
        "  #age_sec1 = Conv2D(filters=512, kernel_size=3, activation='relu')(age_sec1)\n",
        "  age_sec1 = BatchNormalization()(age_sec1)\n",
        "\n",
        "  age_sec2 = MaxPooling2D(pool_size=2)(age_sec1)\n",
        "  #age_sec2 = Concatenate(axis= 1)([age_sec2,mix_sec2])\n",
        "\n",
        "  age_sec3 = Conv2D(filters=256, kernel_size=3, activation='relu')(age_sec2)\n",
        "  #age_sec3 = Conv2D(filters=256, kernel_size=3, activation='relu')(age_sec3)\n",
        "  age_sec3 = BatchNormalization()(age_sec3)\n",
        "\n",
        "  age_sec4 = MaxPooling2D(pool_size=2)(age_sec3)\n",
        "  #age_sec4 = Concatenate(axis= 1)([age_sec4,mix_sec4])\n",
        "\n",
        "  age_sec5 = Conv2D(filters=128, kernel_size=3, activation='relu')(age_sec4)\n",
        "  #age_sec5 = Conv2D(filters=128, kernel_size=3, activation='relu')(age_sec5)\n",
        "  age_sec5 = BatchNormalization()(age_sec5)\n",
        "\n",
        "  age_sec6 = MaxPooling2D(pool_size=2)(age_sec5)\n",
        "  #age_sec6 = Concatenate(axis= 1)([age_sec6,mix_sec6])\n",
        "\n",
        "  age_sec7 = Conv2D(filters=64, kernel_size=3, activation='relu')(age_sec6)\n",
        "  #age_sec7 = Conv2D(filters=64, kernel_size=3, activation='relu')(age_sec7)\n",
        "  age_sec7 = BatchNormalization()(age_sec7)\n",
        "\n",
        "  age_sec8 = MaxPooling2D(pool_size=2)(age_sec7)\n",
        "  #age_sec8 = Concatenate(axis= 1)([age_sec8,mix_sec8])\n",
        "\n",
        "  age_sec9 = Conv2D(filters=32, kernel_size=3, activation='relu')(age_sec8)\n",
        "  age_sec9 = Conv2D(filters=32, kernel_size=3, activation='relu')(age_sec9)\n",
        "  age_sec9 = BatchNormalization()(age_sec9)\n",
        "\n",
        "  age_sec10 = Conv2D(filters=32, kernel_size=3, activation='relu')(age_sec9)\n",
        "  age_sec10 = Conv2D(filters=32, kernel_size=3, activation='relu')(age_sec10)\n",
        "  age_sec10 = BatchNormalization()(age_sec10)\n",
        "\n",
        "  age_sec11 = Flatten(name = 'age_flatten')(age_sec10)\n",
        "\n",
        "  age_sec12 = Dense(1024,activation=\"relu\")(age_sec11)\n",
        "  age_sec12 = Dropout(0.5)(age_sec12)\n",
        "  age_sec12 = Dense(512,activation=\"relu\")(age_sec12)\n",
        "  age_sec12 = Dense(256,activation=\"relu\")(age_sec12)\n",
        "  age_sec12 = Dropout(0.5)(age_sec12)\n",
        "  age_sec12 = Dense(128,activation=\"relu\")(age_sec12)\n",
        "  age_sec12 = Dense(64,activation=\"relu\")(age_sec12)\n",
        "  age_sec12 = Dropout(0.5)(age_sec12)\n",
        "  age_sec12 = Dense(1,activation=\"linear\",name = \"Age_output_layer\")(age_sec12)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model = Model(input_image, outputs= {\"gender_output\" : gender_sec12, \"age_output\": age_sec12})\n",
        "  return model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "km7HpzynhBLQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb4iU1h87x8f",
        "outputId": "36a24a29-704d-402c-a3f2-fc1eac0ca691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 222, 222, 51  14336       ['input_1[0][0]']                \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 222, 222, 51  14336       ['input_1[0][0]']                \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 222, 222, 51  2048       ['conv2d_8[0][0]']               \n",
            " rmalization)                   2)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 222, 222, 51  2048       ['conv2d[0][0]']                 \n",
            " alization)                     2)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 111, 111, 51  0          ['batch_normalization_6[0][0]']  \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 111, 111, 51  0           ['batch_normalization[0][0]']    \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 109, 109, 25  1179904     ['max_pooling2d_4[0][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 109, 109, 25  1179904     ['max_pooling2d[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 109, 109, 25  1024       ['conv2d_9[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 109, 109, 25  1024       ['conv2d_1[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 54, 54, 256)  0          ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 256)  0          ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 52, 52, 128)  295040      ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 52, 52, 128)  295040      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 52, 52, 128)  512        ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 52, 52, 128)  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 26, 26, 128)  0          ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 26, 26, 128)  0          ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 24, 24, 64)   73792       ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 24, 24, 64)   73792       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 24, 24, 64)  256         ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 24, 24, 64)  256         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 64)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 64)  0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 10, 10, 32)   18464       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 10, 10, 32)   18464       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 8, 8, 32)     9248        ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 8, 8, 32)     9248        ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 8, 8, 32)    128         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 8, 8, 32)    128         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 6, 6, 32)     9248        ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 6, 6, 32)     9248        ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 4, 4, 32)     9248        ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 4, 4, 32)     9248        ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 4, 4, 32)    128         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 4, 4, 32)    128         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " age_flatten (Flatten)          (None, 512)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " gender_flatten (Flatten)       (None, 512)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1024)         525312      ['age_flatten[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         525312      ['gender_flatten[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 1024)         0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 512)          524800      ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 512)          524800      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 256)          131328      ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 256)          131328      ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 256)          0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 256)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 128)          32896       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          32896       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 64)           8256        ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 64)           8256        ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 64)           0           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " Age_output_layer (Dense)       (None, 1)            65          ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " Gender_output_layer (Dense)    (None, 1)            65          ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,672,066\n",
            "Trainable params: 5,667,970\n",
            "Non-trainable params: 4,096\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "[INFO] compiling model...\n"
          ]
        }
      ],
      "source": [
        "input_shape = (i_shape, i_shape, 3)\n",
        "optimzer = Adam(learning_rate=0.001)\n",
        "# n_classes=2\n",
        "\n",
        "#model = create_model(input_shape)\n",
        "model = custom_create_model_given(input_shape)\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "losses = {\n",
        "\t\"gender_output\": \"binary_crossentropy\",\n",
        "\t\"age_output\": \"MAE\",\n",
        "}\n",
        "\n",
        "metrics = {\n",
        "    \"gender_output\": \"accuracy\",\n",
        "\t\"age_output\": \"MAE\",\n",
        "}\n",
        "\n",
        "\n",
        "print(\"[INFO] compiling model...\")\n",
        "model.compile(loss=losses, optimizer=optimzer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WYzXCSAV7wLY"
      },
      "outputs": [],
      "source": [
        "#checkpoint = tensorflow.keras.callbacks.ModelCheckpoint('EfficientNetV2B0.h5',  save_best_only=True,monitor='val_loss',mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vh_HhCx3M6Rl"
      },
      "outputs": [],
      "source": [
        "epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "UgxmfW2d7vqs",
        "outputId": "38fc18c7-0fc8-440c-afcc-da1a96ea5199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2/34 [>.............................] - ETA: 44:55 - loss: 15.8392 - Age_output_layer_loss: 15.1452 - Gender_output_layer_loss: 0.6941  "
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f2f5a62ba57a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(train_data_sequence,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data_sequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;31m#batch_size = 16,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     verbose=1)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(train_data_sequence,\n",
        "                    validation_data = test_data_sequence,\n",
        "                    epochs = epochs,\n",
        "                    #batch_size = 16,\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bERHm-N27vGW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QMXvHsd7ufZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpKhKW_l7qn-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k51nulku7tqr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
